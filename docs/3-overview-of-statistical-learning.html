<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>STA 578 - Statistical Computing Notes</title>
  <meta name="description" content="STA 578 - Statistical Computing Notes">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="STA 578 - Statistical Computing Notes" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="STA 578 - Statistical Computing Notes" />
  
  
  

<meta name="author" content="Derek Sonderegger">


<meta name="date" content="2017-10-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="2-markov-chain-monte-carlo.html">
<link rel="next" href="4-classification-with-lda-qda-and-knn.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Computing</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html"><i class="fa fa-check"></i><b>1</b> Data Manipulation</a><ul>
<li class="chapter" data-level="1.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#classic-r-functions-for-summarizing-rows-and-columns"><i class="fa fa-check"></i><b>1.1</b> Classic R functions for summarizing rows and columns</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#summary"><i class="fa fa-check"></i><b>1.1.1</b> <code>summary()</code></a></li>
<li class="chapter" data-level="1.1.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#apply"><i class="fa fa-check"></i><b>1.1.2</b> <code>apply()</code></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#package-dplyr"><i class="fa fa-check"></i><b>1.2</b> Package <code>dplyr</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#verbs"><i class="fa fa-check"></i><b>1.2.1</b> Verbs</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#split-apply-combine"><i class="fa fa-check"></i><b>1.2.2</b> Split, apply, combine</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#chaining-commands-together"><i class="fa fa-check"></i><b>1.2.3</b> Chaining commands together</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#reshaping-data"><i class="fa fa-check"></i><b>1.3</b> Reshaping data</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#tidyr"><i class="fa fa-check"></i><b>1.3.1</b> <code>tidyr</code></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#storing-data-in-multiple-tables"><i class="fa fa-check"></i><b>1.4</b> Storing Data in Multiple Tables</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#table-joins"><i class="fa fa-check"></i><b>1.4.1</b> Table Joins</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#exercises"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#generating-usim-uniform01"><i class="fa fa-check"></i><b>2.1</b> Generating <span class="math inline">\(U\sim Uniform(0,1)\)</span></a></li>
<li class="chapter" data-level="2.2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#inverse-cdf-method"><i class="fa fa-check"></i><b>2.2</b> Inverse CDF Method</a></li>
<li class="chapter" data-level="2.3" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#acceptreject-algorithm"><i class="fa fa-check"></i><b>2.3</b> Accept/Reject Algorithm</a></li>
<li class="chapter" data-level="2.4" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#mcmc-algorithm"><i class="fa fa-check"></i><b>2.4</b> MCMC algorithm</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#mixture-of-normals"><i class="fa fa-check"></i><b>2.4.1</b> Mixture of normals</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#common-problems"><i class="fa fa-check"></i><b>2.4.2</b> Common problems</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#assessing-chain-convergence"><i class="fa fa-check"></i><b>2.4.3</b> Assessing Chain Convergence</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#multi-variate-mcmc"><i class="fa fa-check"></i><b>2.5</b> Multi-variate MCMC</a></li>
<li class="chapter" data-level="2.6" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#hamiltonian-mcmc"><i class="fa fa-check"></i><b>2.6</b> Hamiltonian MCMC</a></li>
<li class="chapter" data-level="2.7" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#exercises-1"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html"><i class="fa fa-check"></i><b>3</b> Overview of Statistical Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.1</b> K-Nearest Neighbors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#knn-for-classification"><i class="fa fa-check"></i><b>3.1.1</b> KNN for Classification</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#knn-for-regression"><i class="fa fa-check"></i><b>3.1.2</b> KNN for Regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#splitting-into-a-test-and-training-sets"><i class="fa fa-check"></i><b>3.2</b> Splitting into a test and training sets</a></li>
<li class="chapter" data-level="3.3" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#exercises-2"><i class="fa fa-check"></i><b>3.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html"><i class="fa fa-check"></i><b>4</b> Classification with LDA, QDA, and KNN</a><ul>
<li class="chapter" data-level="4.1" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#logistic-regression"><i class="fa fa-check"></i><b>4.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#roc-curves"><i class="fa fa-check"></i><b>4.2</b> ROC Curves</a></li>
<li class="chapter" data-level="4.3" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#linear-discriminent-analysis"><i class="fa fa-check"></i><b>4.3</b> Linear Discriminent Analysis</a></li>
<li class="chapter" data-level="4.4" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#quadratic-discriminent-analysis"><i class="fa fa-check"></i><b>4.4</b> Quadratic Discriminent Analysis</a></li>
<li class="chapter" data-level="4.5" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#examples"><i class="fa fa-check"></i><b>4.5</b> Examples</a><ul>
<li class="chapter" data-level="4.5.1" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#iris-data"><i class="fa fa-check"></i><b>4.5.1</b> Iris Data</a></li>
<li class="chapter" data-level="4.5.2" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#detecting-blood-doping"><i class="fa fa-check"></i><b>4.5.2</b> Detecting Blood Doping</a></li>
<li class="chapter" data-level="4.5.3" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#d-example"><i class="fa fa-check"></i><b>4.5.3</b> 2-d Example</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#exercises-3"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>5.1</b> Cross-validation</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#validation-sets-approach"><i class="fa fa-check"></i><b>5.1.1</b> Validation Sets Approach</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#leave-one-out-cross-validation-loocv."><i class="fa fa-check"></i><b>5.1.2</b> Leave one out Cross Validation (LOOCV).</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.1.3</b> K-fold cross validation</a></li>
<li class="chapter" data-level="5.1.4" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#repeated-k-fold-cross-validation"><i class="fa fa-check"></i><b>5.1.4</b> Repeated K-fold cross validation</a></li>
<li class="chapter" data-level="5.1.5" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#using-cross-validation-to-select-a-tuning-parameter"><i class="fa fa-check"></i><b>5.1.5</b> Using cross validation to select a tuning parameter</a></li>
<li class="chapter" data-level="5.1.6" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#comparing-two-analysis-techniques"><i class="fa fa-check"></i><b>5.1.6</b> Comparing two analysis techniques</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#bootstrapping"><i class="fa fa-check"></i><b>5.2</b> Bootstrapping</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#observational-studies-vs-designed-experiments"><i class="fa fa-check"></i><b>5.2.1</b> Observational Studies vs Designed Experiments</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#confidence-interval-types"><i class="fa fa-check"></i><b>5.2.2</b> Confidence Interval Types</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#using-carboot-function"><i class="fa fa-check"></i><b>5.2.3</b> Using <code>car::Boot()</code> function</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#using-the-boot-package"><i class="fa fa-check"></i><b>5.2.4</b> Using the <code>boot</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#exercises-4"><i class="fa fa-check"></i><b>5.3</b> Exercises</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STA 578 - Statistical Computing Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="overview-of-statistical-learning" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Overview of Statistical Learning</h1>
<p>Chapter 2 of <em>Introduction to Statistical Learning</em> is very conceptual and there isn’t much code to mess with, at least until the end. At the end of the chapter, they introduce the machine learning algorithm K-nearest Neighbors but don’t mention anything about how to do an analysis with it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(caret)  <span class="co"># for the train() function</span></code></pre></div>
<p>There are many packages in R that implement a wide variety of machine learning techniques, and each package works in slightly different ways based on the peculiarities of the individual package authors. Unfortunately makes working with these algorithms a pain because we have to learn how each package does things.</p>
<p>The R package <code>caret</code> attempts to resolve this by providing a uniform interface to the most widely used machine learning packages. Whenever possible we will use the <code>caret</code> interface, but there will be times where we have to resort to figuring out the peculiarities of specific packages.</p>
<p>If you are interested in more information about how the <code>caret</code> package works, and what methods are available, I’ve found the <a href="https://cran.r-project.org/web/packages/caret/vignettes/caret.pdf">vignette</a> and <a href="http://topepo.github.io/caret/">manual</a> very helpful. If video tutorials are your thing, there is a <a href="https://www.datacamp.com/courses/machine-learning-toolbox">DataCamp</a> course and the introductory chapter is free.</p>
<div id="k-nearest-neighbors" class="section level2">
<h2><span class="header-section-number">3.1</span> K-Nearest Neighbors</h2>
<p>K-nearest neighbors (KNN) is a technique in machine learning that is extremely simple to implement and extremely easy to understand. We will use this as a prototypical machine learning technique for supervised learning. The idea is that if we wish to predict a response, <span class="math inline">\(\hat{y}_0\)</span> given some covariate(s) <span class="math inline">\(x_0\)</span>, then we look at the <span class="math inline">\(k\)</span> nearest data points to <span class="math inline">\(x_0\)</span> and take the average of those nearest <span class="math inline">\(y\)</span> values (or in the classification setting, the group with highest representation within the <span class="math inline">\(k\)</span> nearest neighbors).</p>
<div id="knn-for-classification" class="section level3">
<h3><span class="header-section-number">3.1.1</span> KNN for Classification</h3>
<p>Suppose we consider the <code>iris</code> dataset and we wish to provide a classifier for iris species based on the sepal length and sepal width.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(iris, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width, <span class="dt">color=</span>Species)) +
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<p>Clearly anything in the upper left should be Setosa, anything in the lower left should be Versicolor, and anything on the right half should be Virginica.</p>
<p>So lets consider KNN.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length +<span class="st"> </span>Sepal.Width, <span class="dt">data=</span>iris, 
               <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span><span class="dv">3</span>))

<span class="co"># expand.grid() makes a data.frame() with all possible combinations</span>
Pred.grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>( <span class="dt">Sepal.Length =</span> <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">8</span>, <span class="dt">length=</span><span class="dv">101</span>),
                          <span class="dt">Sepal.Width  =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="fl">4.5</span>, <span class="dt">length=</span><span class="dv">101</span>) ) 

Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata=</span>Pred.grid)</code></pre></div>
<p>Now that we have the predicted classifications for the grid, lets graph it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Pred.grid, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width)) +
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill=</span>yhat), <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>iris, <span class="kw">aes</span>(<span class="dt">color=</span>Species, <span class="dt">shape=</span>Species)) +
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;dark red&#39;</span>, <span class="st">&#39;dark blue&#39;</span>,<span class="st">&#39;forestgreen&#39;</span>)) +
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;pink&#39;</span>, <span class="st">&#39;light blue&#39;</span>,<span class="st">&#39;cornsilk&#39;</span>)) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;KNN: k=3&#39;</span>)</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>Now we want to see what happens as we vary <span class="math inline">\(k\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Current.K &lt;-<span class="st"> </span><span class="dv">10</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length +<span class="st"> </span>Sepal.Width, <span class="dt">data=</span>iris, 
               <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>Current.K))
Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Pred.grid)

<span class="kw">ggplot</span>(Pred.grid, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width)) +
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill=</span>yhat), <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>iris, <span class="kw">aes</span>(<span class="dt">color=</span>Species, <span class="dt">shape=</span>Species)) +
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;dark red&#39;</span>, <span class="st">&#39;dark blue&#39;</span>,<span class="st">&#39;forestgreen&#39;</span>)) +
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;pink&#39;</span>, <span class="st">&#39;light blue&#39;</span>,<span class="st">&#39;cornsilk&#39;</span>)) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">paste</span>(<span class="st">&#39;KNN: k=&#39;</span>, Current.K, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Current.K &lt;-<span class="st"> </span><span class="dv">50</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length +<span class="st"> </span>Sepal.Width, <span class="dt">data=</span>iris, 
               <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>Current.K))
Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Pred.grid)

<span class="kw">ggplot</span>(Pred.grid, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Sepal.Width)) +
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill=</span>yhat), <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>iris, <span class="kw">aes</span>(<span class="dt">color=</span>Species, <span class="dt">shape=</span>Species)) +
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;dark red&#39;</span>, <span class="st">&#39;dark blue&#39;</span>,<span class="st">&#39;forestgreen&#39;</span>)) +
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;pink&#39;</span>, <span class="st">&#39;light blue&#39;</span>,<span class="st">&#39;cornsilk&#39;</span>)) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">paste</span>(<span class="st">&#39;KNN: k=&#39;</span>, Current.K, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
</div>
<div id="knn-for-regression" class="section level3">
<h3><span class="header-section-number">3.1.2</span> KNN for Regression</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">8675309</span>)
n &lt;-<span class="st"> </span><span class="dv">50</span>
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">x=</span><span class="kw">seq</span>(.<span class="dv">5</span>,<span class="dv">3</span>, <span class="dt">length=</span>n) ) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">Ey =</span> <span class="dv">2</span> -<span class="st"> </span><span class="dv">4</span>*x +<span class="st"> </span><span class="dv">3</span>*x^<span class="dv">2</span> -<span class="st"> </span>.<span class="dv">55</span>*x^<span class="dv">3</span> +<span class="st"> </span><span class="kw">cos</span>(x),
           <span class="dt">y =</span> Ey +<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd=</span>.<span class="dv">1</span>))
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>x)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Ey)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>y)) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">main=</span><span class="st">&#39;foo&#39;</span>, <span class="dt">y=</span><span class="st">&#39;y&#39;</span>, <span class="dt">title=</span><span class="st">&#39;Made up data&#39;</span>)</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># values of x where we wish to make a prediction</span>
Pred.grid &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="fl">0.5</span>, <span class="dv">3</span>, <span class="dt">length=</span><span class="dv">1001</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Current.K &lt;-<span class="st"> </span><span class="dv">3</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(y~x, <span class="dt">data=</span>data, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>Current.K))
Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Pred.grid)

<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>x)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Ey)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>y)) +
<span class="st">  </span><span class="kw">geom_line</span>( <span class="dt">data=</span>Pred.grid, <span class="kw">aes</span>(<span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">main=</span><span class="st">&#39;foo&#39;</span>, <span class="dt">y=</span><span class="st">&#39;y&#39;</span>, <span class="dt">title=</span><span class="kw">paste</span>(<span class="st">&#39;KNN: k=&#39;</span>, Current.K, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-114-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Current.K &lt;-<span class="st"> </span><span class="dv">10</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(y~x, <span class="dt">data=</span>data, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>Current.K))
Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Pred.grid)

<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>x)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Ey)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>y)) +
<span class="st">  </span><span class="kw">geom_line</span>( <span class="dt">data=</span>Pred.grid, <span class="kw">aes</span>(<span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">main=</span><span class="st">&#39;foo&#39;</span>, <span class="dt">y=</span><span class="st">&#39;y&#39;</span>, <span class="dt">title=</span><span class="kw">paste</span>(<span class="st">&#39;KNN: k=&#39;</span>, Current.K, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-115-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Current.K &lt;-<span class="st"> </span><span class="dv">50</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(y~x, <span class="dt">data=</span>data, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>Current.K))
Pred.grid$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Pred.grid)

<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>x)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Ey)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>y)) +
<span class="st">  </span><span class="kw">geom_line</span>( <span class="dt">data=</span>Pred.grid, <span class="kw">aes</span>(<span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">main=</span><span class="st">&#39;foo&#39;</span>, <span class="dt">y=</span><span class="st">&#39;y&#39;</span>, <span class="dt">title=</span><span class="kw">paste</span>(<span class="st">&#39;KNN: k=&#39;</span>, Current.K, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>))</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-116-1.png" width="672" /></p>
</div>
</div>
<div id="splitting-into-a-test-and-training-sets" class="section level2">
<h2><span class="header-section-number">3.2</span> Splitting into a test and training sets</h2>
<p>We continue to consider the Regression problem but we now consider splitting the data into Training and Test sets and comparing the Root Mean Squared Error (RMSE) of Test sets for various values of <span class="math inline">\(K\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Train &lt;-<span class="st"> </span>data %&gt;%<span class="st"> </span><span class="kw">sample_frac</span>(.<span class="dv">5</span>)
Test  &lt;-<span class="st"> </span><span class="kw">setdiff</span>(data, Train)

K &lt;-<span class="st"> </span><span class="dv">5</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(y ~<span class="st"> </span>x, <span class="dt">data=</span>Train, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>K) )
Test$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Test)
Test %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">resid =</span> y-yhat) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">Test.RMSE =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>( resid^<span class="dv">2</span> )), <span class="dt">K =</span> K)</code></pre></div>
<pre><code>##   Test.RMSE K
## 1 0.1107162 5</code></pre>
<p>Now that we see how to calculate the Test Mean Squared Error, lets look at a range of values for <span class="math inline">\(K\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Results &lt;-<span class="st"> </span><span class="ot">NULL</span>
for(K in <span class="dv">1</span>:<span class="dv">25</span>){
  model &lt;-<span class="st"> </span><span class="kw">train</span>(y ~<span class="st"> </span>x, <span class="dt">data=</span>Train, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span>K) )
  Test$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, Test)
  
  Temp &lt;-<span class="st"> </span>Test %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">resid =</span> y-yhat) %&gt;%
<span class="st">      </span><span class="kw">summarise</span>( <span class="dt">Test.RMSE =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>( resid^<span class="dv">2</span> )), <span class="dt">K =</span> K)
  Results &lt;-<span class="st"> </span><span class="kw">rbind</span>(Results, Temp)
}</code></pre></div>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info =
## trainInfo, : There were missing values in resampled performance measures.

## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info =
## trainInfo, : There were missing values in resampled performance measures.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Results, <span class="kw">aes</span>(<span class="dt">x=</span>K, <span class="dt">y=</span>Test.RMSE)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">scale_x_reverse</span>() <span class="co"># so model complexity increases along x-axis.</span></code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-119-1.png" width="672" /></p>
</div>
<div id="exercises-2" class="section level2">
<h2><span class="header-section-number">3.3</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>ISL 2.1: For each part below, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.
<ol style="list-style-type: lower-alpha">
<li>The sample size n is extremely large, and the number of predictors p is small.</li>
<li>The number of predictors p is extremely large, and the number of observations n is small.</li>
<li>Relationship between the predictors and response is highly non-linear.</li>
<li>The variance of the error terms, i.e. <span class="math inline">\(\sigma^{2}=Var\left(\epsilon\right)\)</span>, is extremely high.</li>
</ol></li>
<li>ISL 2.2: Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>.
<ol style="list-style-type: lower-alpha">
<li>We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.</li>
<li>We are considering launching a new product and wish to know whether it will be a <code>success</code> or <code>failure</code>. We collect data on 20 similar products that were previously launched. For each product we have record whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.</li>
<li>We are interested in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.</li>
</ol></li>
<li>ISL 2.3: We new revisit the bias-variance decomposition.
<ol style="list-style-type: lower-alpha">
<li>Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.</li>
<li>Explain why each of the five curves has the shape displayed in part (a).</li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-markov-chain-monte-carlo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-classification-with-lda-qda-and-knn.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/578/raw/master/03_Overview.Rmd",
"text": "Edit"
},
"download": [["Statistical_Computing_Notes.pdf", "PDF"], ["Statistical_Computing_Notes.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
