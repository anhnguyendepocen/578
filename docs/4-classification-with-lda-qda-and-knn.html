<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>STA 578 - Statistical Computing Notes</title>
  <meta name="description" content="STA 578 - Statistical Computing Notes">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="STA 578 - Statistical Computing Notes" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="STA 578 - Statistical Computing Notes" />
  
  
  

<meta name="author" content="Derek Sonderegger">


<meta name="date" content="2017-10-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="3-overview-of-statistical-learning.html">
<link rel="next" href="5-resampling-methods.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Computing</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html"><i class="fa fa-check"></i><b>1</b> Data Manipulation</a><ul>
<li class="chapter" data-level="1.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#classic-r-functions-for-summarizing-rows-and-columns"><i class="fa fa-check"></i><b>1.1</b> Classic R functions for summarizing rows and columns</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#summary"><i class="fa fa-check"></i><b>1.1.1</b> <code>summary()</code></a></li>
<li class="chapter" data-level="1.1.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#apply"><i class="fa fa-check"></i><b>1.1.2</b> <code>apply()</code></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#package-dplyr"><i class="fa fa-check"></i><b>1.2</b> Package <code>dplyr</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#verbs"><i class="fa fa-check"></i><b>1.2.1</b> Verbs</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#split-apply-combine"><i class="fa fa-check"></i><b>1.2.2</b> Split, apply, combine</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#chaining-commands-together"><i class="fa fa-check"></i><b>1.2.3</b> Chaining commands together</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#reshaping-data"><i class="fa fa-check"></i><b>1.3</b> Reshaping data</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#tidyr"><i class="fa fa-check"></i><b>1.3.1</b> <code>tidyr</code></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#storing-data-in-multiple-tables"><i class="fa fa-check"></i><b>1.4</b> Storing Data in Multiple Tables</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#table-joins"><i class="fa fa-check"></i><b>1.4.1</b> Table Joins</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-data-manipulation.html"><a href="1-data-manipulation.html#exercises"><i class="fa fa-check"></i><b>1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#generating-usim-uniform01"><i class="fa fa-check"></i><b>2.1</b> Generating <span class="math inline">\(U\sim Uniform(0,1)\)</span></a></li>
<li class="chapter" data-level="2.2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#inverse-cdf-method"><i class="fa fa-check"></i><b>2.2</b> Inverse CDF Method</a></li>
<li class="chapter" data-level="2.3" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#acceptreject-algorithm"><i class="fa fa-check"></i><b>2.3</b> Accept/Reject Algorithm</a></li>
<li class="chapter" data-level="2.4" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#mcmc-algorithm"><i class="fa fa-check"></i><b>2.4</b> MCMC algorithm</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#mixture-of-normals"><i class="fa fa-check"></i><b>2.4.1</b> Mixture of normals</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#common-problems"><i class="fa fa-check"></i><b>2.4.2</b> Common problems</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#assessing-chain-convergence"><i class="fa fa-check"></i><b>2.4.3</b> Assessing Chain Convergence</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#multi-variate-mcmc"><i class="fa fa-check"></i><b>2.5</b> Multi-variate MCMC</a></li>
<li class="chapter" data-level="2.6" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#hamiltonian-mcmc"><i class="fa fa-check"></i><b>2.6</b> Hamiltonian MCMC</a></li>
<li class="chapter" data-level="2.7" data-path="2-markov-chain-monte-carlo.html"><a href="2-markov-chain-monte-carlo.html#exercises-1"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html"><i class="fa fa-check"></i><b>3</b> Overview of Statistical Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.1</b> K-Nearest Neighbors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#knn-for-classification"><i class="fa fa-check"></i><b>3.1.1</b> KNN for Classification</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#knn-for-regression"><i class="fa fa-check"></i><b>3.1.2</b> KNN for Regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#splitting-into-a-test-and-training-sets"><i class="fa fa-check"></i><b>3.2</b> Splitting into a test and training sets</a></li>
<li class="chapter" data-level="3.3" data-path="3-overview-of-statistical-learning.html"><a href="3-overview-of-statistical-learning.html#exercises-2"><i class="fa fa-check"></i><b>3.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html"><i class="fa fa-check"></i><b>4</b> Classification with LDA, QDA, and KNN</a><ul>
<li class="chapter" data-level="4.1" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#logistic-regression"><i class="fa fa-check"></i><b>4.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#roc-curves"><i class="fa fa-check"></i><b>4.2</b> ROC Curves</a></li>
<li class="chapter" data-level="4.3" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#linear-discriminent-analysis"><i class="fa fa-check"></i><b>4.3</b> Linear Discriminent Analysis</a></li>
<li class="chapter" data-level="4.4" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#quadratic-discriminent-analysis"><i class="fa fa-check"></i><b>4.4</b> Quadratic Discriminent Analysis</a></li>
<li class="chapter" data-level="4.5" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#examples"><i class="fa fa-check"></i><b>4.5</b> Examples</a><ul>
<li class="chapter" data-level="4.5.1" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#iris-data"><i class="fa fa-check"></i><b>4.5.1</b> Iris Data</a></li>
<li class="chapter" data-level="4.5.2" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#detecting-blood-doping"><i class="fa fa-check"></i><b>4.5.2</b> Detecting Blood Doping</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-classification-with-lda-qda-and-knn.html"><a href="4-classification-with-lda-qda-and-knn.html#exercises-3"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>5.1</b> Cross-validation</a></li>
<li class="chapter" data-level="5.2" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#validation-sets-approach"><i class="fa fa-check"></i><b>5.2</b> Validation Sets Approach</a></li>
<li class="chapter" data-level="5.3" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.3</b> Leave One out Cross Validation</a></li>
<li class="chapter" data-level="5.4" data-path="5-resampling-methods.html"><a href="5-resampling-methods.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.4</b> k-fold Cross Validation</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STA 578 - Statistical Computing Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification-with-lda-qda-and-knn" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Classification with LDA, QDA, and KNN</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">library</span>(MASS)     <span class="co"># lda function used by caret</span>
<span class="kw">library</span>(dplyr)    <span class="co"># data frame manipulations</span>
<span class="kw">library</span>(ggplot2)  <span class="co"># plotting</span>
<span class="kw">library</span>(STA578)   <span class="co"># for my multiplot() function</span>
<span class="kw">library</span>(pROC)     <span class="co"># All the ROC stuff</span></code></pre></div>
<p>In this chapter we look at several forms of classification. In particular we will focus on the classical techniques of logistic regression, Linear Discriminent Analysis and Quadratic Discriminent Analysis.</p>
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">4.1</span> Logistic Regression</h2>
<p>We won’t cover the theory of logistic regression here, but you can find it <a href="https://dereksonderegger.github.io/571/12-binomial-regression.html">elsewhere</a>.</p>
<p>The dataset <code>faraway::wbca</code> comes from a study of breast cancer in Wisconsin. There are 681 cases of potentially cancerous tumors of which 238 are actually malignant (ie cancerous). Determining whether a tumor is really malignant is traditionally determined by an invasive surgical procedure. The purpose of this study was to determine whether a new procedure called ‘fine needle aspiration’, which draws only a small sample of tissue, could be effective in determining tumor status.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&#39;wbca&#39;</span>, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)

<span class="co"># clean up the data</span>
wbca &lt;-<span class="st"> </span>wbca %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="kw">ifelse</span>(Class==<span class="dv">0</span>, <span class="st">&#39;malignant&#39;</span>, <span class="st">&#39;benign&#39;</span>)) %&gt;%
<span class="st">  </span>dplyr::<span class="kw">select</span>(Class, BNucl, UShap, USize) 

<span class="co"># Fit the model</span>
<span class="co"># Malignant is considered a success</span>
model &lt;-<span class="st"> </span><span class="kw">glm</span>( <span class="kw">I</span>(Class==<span class="st">&#39;malignant&#39;</span>) ~<span class="st"> </span>., <span class="dt">data=</span>wbca, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span> )

<span class="co"># Get the response values</span>
<span class="co"># type=&#39;response&#39; gives phat values which live in [0,1]</span>
<span class="co"># type=&#39;link&#39; gives the Xbeta values whice live in (-infinity, infinity)</span>
wbca &lt;-<span class="st"> </span>wbca %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">phat =</span> <span class="kw">predict</span>(model, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>),
         <span class="dt">yhat =</span> <span class="kw">ifelse</span>(phat &gt;<span class="st"> </span>.<span class="dv">5</span>, <span class="st">&#39;malignant&#39;</span>, <span class="st">&#39;benign&#39;</span>))

<span class="co"># Calculate the confusion matrix</span>
<span class="kw">table</span>( <span class="dt">Truth=</span>wbca$Class, <span class="dt">Predicted=</span>wbca$yhat )</code></pre></div>
<pre><code>##            Predicted
## Truth       benign malignant
##   benign       432        11
##   malignant     15       223</code></pre>
<p>As usual we can calculate the summary tables…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = I(Class == &quot;malignant&quot;) ~ ., family = &quot;binomial&quot;, 
##     data = wbca)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8890  -0.1409  -0.1409   0.0287   2.2284  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -6.35433    0.54076 -11.751  &lt; 2e-16 ***
## BNucl        0.55297    0.08041   6.877 6.13e-12 ***
## UShap        0.62583    0.17506   3.575 0.000350 ***
## USize        0.56793    0.15910   3.570 0.000358 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 881.39  on 680  degrees of freedom
## Residual deviance: 148.43  on 677  degrees of freedom
## AIC: 156.43
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<p>From this table, we see that for a breast tumor, the larger values of <code>BNucl</code>, <code>UShap</code>, and <code>USize</code> imply a greater probability of it being malignant. So for a tumor with</p>
<pre><code>##   BNucl UShap USize
## 1     2     1     2</code></pre>
<p>We would calculate <span class="math display">\[\begin{aligned} X \hat{\beta} 
  &amp;= \hat{\beta}_0 + 2 \cdot \hat{\beta}_1 + 1 \cdot \hat{\beta}_2 + 2 \cdot \hat{\beta}_3 \\
  &amp;= -6.35 + 2*(0.553) + 1*(0.626) + 2*(0.568) \\
  &amp;= -3.482
  \end{aligned}\]</span></p>
<p>and therefore <span class="math display">\[\hat{p} = \frac{1}{1+e^{-X\hat{\beta}}} = \frac{1}{1+e^{3.482}} = 0.0297\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata =<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">BNucl=</span><span class="dv">2</span>, <span class="dt">UShap=</span><span class="dv">1</span>, <span class="dt">USize=</span><span class="dv">2</span> )
<span class="kw">predict</span>(model, <span class="dt">newdata=</span>newdata)</code></pre></div>
<pre><code>##         1 
## -3.486719</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(model, <span class="dt">newdata=</span>newdata, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)</code></pre></div>
<pre><code>##         1 
## 0.0296925</code></pre>
<p>So for a tumor with these covariates, we would classify it as most likely to be benign.</p>
</div>
<div id="roc-curves" class="section level2">
<h2><span class="header-section-number">4.2</span> ROC Curves</h2>
<p>In the medical scenario where we have to decide if a tumor is malignant of benign, we shouldn’t treat the misclassification errors as being the same. If we incorrectly identify a tumor as malignant when it is not, that will cause a patient to undergo a somewhat invasive surgury to remove the tumor. However if we incorrectly identify a tumor as being benign, then the cancerous tumor will likely grow and eventually kill the patient. While the first error is regretable, the second is far worse.</p>
<p>Given that reasoning, perhaps we shouldn’t use the rule: If <span class="math inline">\(\hat{p} &gt;= 0.5\)</span> classify as malignant. Instead perhaps we should use <span class="math inline">\(\hat{p} &gt;= 0.3\)</span> or <span class="math inline">\(\hat{p} &gt;= 0.05\)</span>.</p>
<p>Whatever decision rule we make, we should consider how many of each type of error we make. Consider the following confusion maatrix:</p>
<table style="width:96%;">
<colgroup>
<col width="22%" />
<col width="30%" />
<col width="30%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Predict Positive</th>
<th align="center">Predict Negative</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Positive</strong></td>
<td align="center">True Pos (TP)</td>
<td align="center">False Neg (FN)</td>
<td align="center"><span class="math inline">\(P\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>Negative</strong></td>
<td align="center">False Pos (FP)</td>
<td align="center">True Neg (TN)</td>
<td align="center"><span class="math inline">\(N\)</span></td>
</tr>
<tr class="odd">
<td align="center"><strong>Total</strong></td>
<td align="center"><span class="math inline">\(P^*\)</span></td>
<td align="center"><span class="math inline">\(N^*\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>where <span class="math inline">\(P\)</span> is the number of positive cases, <span class="math inline">\(N\)</span> is the number of negative cases, <span class="math inline">\(P^*\)</span> is the number of observations predicted to be positive, and <span class="math inline">\(N^*\)</span> is the number predicted to be negative.</p>
<table style="width:88%;">
<colgroup>
<col width="30%" />
<col width="15%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th>Quantity</th>
<th>Formula</th>
<th>Synonyms</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>False Positive Rate</p></td>
<td><p><span class="math inline">\(FP/N\)</span></p></td>
<td><p>Type I Error; 1-Specificity</p></td>
</tr>
<tr class="even">
<td><p>True Positive Rate</p></td>
<td><p><span class="math inline">\(TP/P\)</span></p></td>
<td><p>Power; Sensitivity; Recall</p></td>
</tr>
<tr class="odd">
<td><p>Pos. Pred. Value</p></td>
<td><p><span class="math inline">\(TP/P^*\)</span></p></td>
<td><p>Precision</p></td>
</tr>
</tbody>
</table>
<p>We can think of the True Positive Rate as the probability that a Positive case will be correctly classified as a positive. Similarly a False Positive Rate is the probability that a Negative case will be incorrectly classified as a positive.</p>
<p>I wish to examine the relationship between the False Positive Rate and the True Positive Rate for any decision rule. So what we could do is select a sequence of decision rules and for each calculate the <code>(FPR, TPR)</code> pair, and then make a plot where we play connect the dots with the <code>(FPR, TPR)</code> pairs.</p>
<p>Of course we don’t want to have to do this by hand, so we’ll use the package <code>pROC</code> to do it for us.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the ROC information using pROC::roc()</span>
myROC &lt;-<span class="st"> </span><span class="kw">roc</span>( wbca$Class,  wbca$phat )

<span class="co"># make a nice plot using ggplot2 and pROC::ggroc()</span>
<span class="kw">ggroc</span>( myROC ) </code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-126-1.png" width="672" /></p>
<p>This looks pretty good and in an ideal classifier that makes prefect predictions, this would be a perfect right angle at the bend.</p>
<p>Lets zoom in a little on the high specificity values (i.e. low false positive rates)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggroc</span>( myROC ) +<span class="st"> </span><span class="kw">xlim</span>(<span class="dv">1</span>, .<span class="dv">9</span>)</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-127-1.png" width="672" /></p>
<p>We see that if we want to correctly identify about 99% of maligant tumors, we will have a false positive rate of about 1-0.95 = 0.05. So about 5% of benign tumors would be incorrectly classified as malignant.</p>
<p>It is a little challenging to read the graph to see what the Sensitivity is for a particular value of Specificity. To do this we’ll use another function because the authors would prefer you to also estimate the confidence intervals for the quantity. This is a case where bootstrap confidence intervals are quite effective.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ci</span>(myROC, <span class="dt">of=</span><span class="st">&#39;sp&#39;</span>, <span class="dt">sensitivities=</span>.<span class="dv">99</span>)</code></pre></div>
<pre><code>## 95% CI (2000 stratified bootstrap replicates):
##    se sp.low sp.median sp.high
##  0.99 0.9232    0.9571  0.9797</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ci</span>(myROC, <span class="dt">of=</span><span class="st">&#39;se&#39;</span>, <span class="dt">specificities=</span>.<span class="dv">975</span>)</code></pre></div>
<pre><code>## 95% CI (2000 stratified bootstrap replicates):
##     sp se.low se.median se.high
##  0.975 0.8866     0.937  0.9958</code></pre>
<p>One measure of how far we are from the perfect predictor is the area under the curve. The perfect model would have an area under the curve of 1. For this model the area under the curve is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">auc</span>(myROC) </code></pre></div>
<pre><code>## Area under the curve: 0.9929</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ci</span>(myROC, <span class="dt">of=</span><span class="st">&#39;auc&#39;</span>)</code></pre></div>
<pre><code>## 95% CI: 0.9878-0.9981 (DeLong)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ci</span>(myROC, <span class="dt">of=</span><span class="st">&#39;auc&#39;</span>, <span class="dt">method=</span><span class="st">&#39;bootstrap&#39;</span>)</code></pre></div>
<pre><code>## 95% CI: 0.987-0.9975 (2000 stratified bootstrap replicates)</code></pre>
<p>which seems pretty good and Area Under the Curve (AUC) is often used as a way of comparing the quality of binary classifiers.</p>
</div>
<div id="linear-discriminent-analysis" class="section level2">
<h2><span class="header-section-number">4.3</span> Linear Discriminent Analysis</h2>
<p>Discriminent analysis classification techniques assume that we have a categorical (possibly unordered) response <span class="math inline">\(y\)</span> and a continuous covariate predictor <span class="math inline">\(x\)</span>. In many ways we can consider this the inverse problem of a 1-way anova.</p>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-130-1.png" width="672" /></p>
<p>Because we are doing ANOVA in reverse, we assume the same relationship between the groups and the continuous covariate, namely that <span class="math display">\[x_{ij} \stackrel{iid}{\sim} N\left( \mu_i, \sigma^2 \right)\]</span></p>
<p>So to fit normal distributions, we just need to estimate values for the mean of each group <span class="math inline">\(\hat{\mu}_i\)</span> and something for the overal variance, <span class="math inline">\(\hat{\sigma}^2\)</span>.</p>
<p>We will use the individual sample means for <span class="math inline">\(\hat{\mu}_i\)</span> and the pooled variance estimator for <span class="math inline">\(\hat{\sigma}^2\)</span>. Let <span class="math inline">\(k\)</span> be the number of groups, <span class="math inline">\(n_i\)</span> be the number of samples in group <span class="math inline">\(i\)</span>, and <span class="math inline">\(n=n_1 + \dots + n_k\)</span> be the total number of observations.</p>
<p><span class="math display">\[\hat{\mu}_i = \bar{x}_i = \frac{1}{n_i} \sum_{j=1}^{n_i} x_{ij}\]</span></p>
<p><span class="math display">\[\begin{aligned} \hat{\sigma}^2 
  &amp;= \frac{1}{n-k} \sum_{i=1}^k \sum_{j=1}^{n_i} (x_{ij} - \hat{\mu}_i)^2\\
  &amp;= \frac{1}{n-k} \sum_{i=1}^k (n_i-1) s^2_i
  \end{aligned}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(data)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    90 obs. of  2 variables:
##  $ x    : num  6.04 10.33 4.97 2.44 9.19 ...
##  $ Group: Factor w/ 3 levels &quot;G1&quot;,&quot;G2&quot;,&quot;G3&quot;: 1 2 3 1 2 3 1 2 3 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(data)
k &lt;-<span class="st"> </span><span class="kw">length</span>( <span class="kw">levels</span>( data$Group ))

<span class="co"># calculate group level statistics and pooled variance</span>
params &lt;-<span class="st"> </span>data %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(Group) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>(x),
             <span class="dt">s2_i =</span> <span class="kw">var</span>(x),
             <span class="dt">n_i  =</span> <span class="kw">n</span>() ) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">s2 =</span> <span class="kw">sum</span>( (n_i -<span class="dv">1</span>)*s2_i ) /<span class="st"> </span>(n-k) )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the k curves</span>
newdata &lt;-<span class="st"> </span><span class="kw">expand.grid</span>( <span class="dt">x=</span><span class="kw">seq</span>(-<span class="dv">1</span>,<span class="dv">13</span>, <span class="dt">by=</span><span class="fl">0.01</span>), <span class="dt">Group=</span><span class="kw">paste</span>(<span class="st">&#39;G&#39;</span>, <span class="dv">1</span>:<span class="dv">3</span>, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>) ) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(params, <span class="dt">by=</span><span class="st">&#39;Group&#39;</span>) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">f =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean=</span>xbar, <span class="dt">sd=</span><span class="kw">sqrt</span>(s2) ) )
P2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(newdata, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>f, <span class="dt">color=</span>Group)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span><span class="kw">xlim</span>(-<span class="dv">1</span>, <span class="dv">13</span>) +
<span class="st">  </span><span class="kw">labs</span>( <span class="dt">y=</span><span class="st">&#39;f(x)&#39;</span> )

<span class="kw">multiplot</span>(P1, P2, <span class="dt">ncol=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-132-1.png" width="672" /></p>
<p>Now for any value along the x-axis, say <span class="math inline">\(x^*\)</span>, we predict <span class="math inline">\(y^*\)</span> as whichever group with the largest <span class="math inline">\(\hat{f}_i(x^*)\)</span>.</p>
</div>
<div id="quadratic-discriminent-analysis" class="section level2">
<h2><span class="header-section-number">4.4</span> Quadratic Discriminent Analysis</h2>
<p>The only difference between linear discriminent analysis and quadratic, is that we know allow for the groups to have different variance terms. <span class="math display">\[x_{ij} \stackrel{iid}{\sim} N\left( \mu_i, \sigma^2_i \right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(data)
k &lt;-<span class="st"> </span><span class="kw">length</span>( <span class="kw">levels</span>( data$Group ))

<span class="co"># calculate group level statistics and pooled variance</span>
params &lt;-<span class="st"> </span>data %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(Group) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">xbar =</span> <span class="kw">mean</span>(x),
             <span class="dt">s2_i =</span> <span class="kw">var</span>(x),
             <span class="dt">n_i  =</span> <span class="kw">n</span>() )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the k curves</span>
newdata &lt;-<span class="st"> </span><span class="kw">expand.grid</span>( <span class="dt">x=</span><span class="kw">seq</span>(-<span class="dv">1</span>,<span class="dv">13</span>, <span class="dt">by=</span><span class="fl">0.01</span>), <span class="dt">Group=</span><span class="kw">paste</span>(<span class="st">&#39;G&#39;</span>, <span class="dv">1</span>:<span class="dv">3</span>, <span class="dt">sep=</span><span class="st">&#39;&#39;</span>) ) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(params, <span class="dt">by=</span><span class="st">&#39;Group&#39;</span>) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">f =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean=</span>xbar, <span class="dt">sd=</span><span class="kw">sqrt</span>(s2_i) ) )
P2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(newdata, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>f, <span class="dt">color=</span>Group)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span><span class="kw">xlim</span>(-<span class="dv">1</span>, <span class="dv">13</span>) +
<span class="st">  </span><span class="kw">labs</span>( <span class="dt">y=</span><span class="st">&#39;f(x)&#39;</span> )

<span class="kw">multiplot</span>(P1, P2, <span class="dt">ncol=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-134-1.png" width="672" /></p>
<p>The decision to classify a point <span class="math inline">\(x^*, y^*\)</span> as in a particular group is often too stark of a decision, and we would like to assess the certainty of the assignment. We define the <em>posterior probability</em> of the point as coming from group <span class="math inline">\(i\)</span> as <span class="math display">\[P( y^* = i | x^* ) = \frac{ \hat{f}_i(x^*) }{ \sum_j \hat{f}_j(x^*) }\]</span></p>
<p>That is, add up the heights of all the curves at <span class="math inline">\(x^*\)</span> and then use the percent contribution of each to the total as the probability.</p>
</div>
<div id="examples" class="section level2">
<h2><span class="header-section-number">4.5</span> Examples</h2>
<div id="iris-data" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Iris Data</h3>
<p>Recall the iris data set is 150 observations that measure leaf and sepal characteristics for three different species of iris. We’ll use the leaf characteristics to try to produce a classification rule.</p>
<p>We will first split this into a training data set and a test data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>( <span class="dv">8675309</span> )  <span class="co"># so that the same training set is chosen every time...</span>
iris$Obs_ID &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="dv">150</span> <span class="co"># there are a couple of identical rows, we don&#39;t like that</span>

<span class="co"># random select 1/2 from each species to be the training set</span>
train &lt;-<span class="st"> </span>iris %&gt;%<span class="st"> </span><span class="kw">group_by</span>(Species) %&gt;%<span class="st"> </span><span class="kw">sample_n</span>( <span class="dv">25</span> )
test  &lt;-<span class="st"> </span><span class="kw">setdiff</span>(iris, train)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(train, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">color=</span>Species)) +
<span class="st">   </span><span class="kw">geom_density</span>()</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-136-1.png" width="576" /></p>
<p>While these certainly aren’t normal and it isn’t clear that the equal variance amongst groups is accurate, there is nothing that prevents us from assuming so and just doing LDA.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train %&gt;%<span class="st"> </span><span class="kw">group_by</span>(Species) %&gt;%<span class="st"> </span>
<span class="st">   </span><span class="kw">summarize</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(Sepal.Length),
             <span class="dt">sd   =</span> <span class="kw">sd</span>(Sepal.Length))</code></pre></div>
<pre><code>## # A tibble: 3 x 3
##      Species  xbar        sd
##       &lt;fctr&gt; &lt;dbl&gt;     &lt;dbl&gt;
## 1     setosa 4.988 0.3756328
## 2 versicolor 5.812 0.5027591
## 3  virginica 6.412 0.5946427</code></pre>
<p>We’ll predict setosa if x &lt; (4.988 + 5.812)/2 = 5.4. We’ll predict versicolor if 5.4 &lt; x &lt; (5.812 + 6.412)/2 = 6.1 We’ll predict versicolor if 6.1 &lt; x</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># have R do this</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length, <span class="dt">method=</span><span class="st">&#39;lda&#39;</span>, <span class="dt">data=</span>train)
test$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata=</span>test)
<span class="kw">table</span>( <span class="dt">Truth=</span>test$Species, <span class="dt">Prediction=</span>test$yhat )</code></pre></div>
<pre><code>##             Prediction
## Truth        setosa versicolor virginica
##   setosa         22          3         0
##   versicolor      1         15         9
##   virginica       0          4        21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(test, <span class="kw">aes</span>(<span class="dt">x=</span>Sepal.Length, <span class="dt">y=</span>Species, <span class="dt">color=</span>yhat) ) +<span class="st"> </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-138-1.png" width="672" /> This is a little hard to read, but of the 25 observations that we know are setosa, 3 of them have been misclassified as versicolor. Likewise, of the 25 observations that are virginica, 21 are correctly identified as virginica while 4 are misclassified as versicolor. So out of 75 test cases, we correctly classified 57, and incorrectly classified 17.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the Misclassification rate</span>
<span class="dv">17</span>/<span class="dv">75</span></code></pre></div>
<pre><code>## [1] 0.2266667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">misclassification_rate =</span> <span class="kw">mean</span>( Species !=<span class="st"> </span>yhat ) )</code></pre></div>
<pre><code>##   misclassification_rate
## 1              0.2266667</code></pre>
<p>Next, we will relax the assumption that the distributions have equal variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># have R do this</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length, <span class="dt">method=</span><span class="st">&#39;qda&#39;</span>, <span class="dt">data=</span>train)
test$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata=</span>test)
<span class="kw">table</span>( <span class="dt">Truth=</span>test$Species, <span class="dt">Prediction=</span>test$yhat )</code></pre></div>
<pre><code>##             Prediction
## Truth        setosa versicolor virginica
##   setosa         24          1         0
##   versicolor      1         15         9
##   virginica       0          4        21</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">misclassification_rate =</span> <span class="kw">mean</span>( Species !=<span class="st"> </span>yhat ) )</code></pre></div>
<pre><code>##   misclassification_rate
## 1                    0.2</code></pre>
<p>This has improved our accuracy as 2 setosa observations that were previously misclassified are now correctly classified.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># What about KNN?</span>
model &lt;-<span class="st"> </span><span class="kw">train</span>(Species ~<span class="st"> </span>Sepal.Length, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">k=</span><span class="dv">3</span>), <span class="dt">data=</span>train)
test$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata=</span>test)
<span class="kw">table</span>( <span class="dt">Truth=</span>test$Species, <span class="dt">Prediction=</span>test$yhat )</code></pre></div>
<pre><code>##             Prediction
## Truth        setosa versicolor virginica
##   setosa         19          6         0
##   versicolor      2         13        10
##   virginica       0          5        20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test %&gt;%
<span class="st">  </span><span class="kw">summarise</span>( <span class="dt">misclassification_rate =</span> <span class="kw">mean</span>( Species !=<span class="st"> </span>yhat ) )</code></pre></div>
<pre><code>##   misclassification_rate
## 1              0.3066667</code></pre>
</div>
<div id="detecting-blood-doping" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Detecting Blood Doping</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(devtools)
<span class="kw">install_github</span>(<span class="st">&#39;dereksonderegger/dsData&#39;</span>)</code></pre></div>
<pre><code>## Skipping install of &#39;dsData&#39; from a github remote, the SHA1 (208be54a) has not changed since last install.
##   Use `force = TRUE` to force installation</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dsData)</code></pre></div>
<p>We now consider a case where the number of observations is not the same between groups. Here we consider the case where we are interested in using hemocrit levels to detect if a cyclist is cheating.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&#39;Hemocrit&#39;</span>, <span class="dt">package=</span><span class="st">&#39;dsData&#39;</span>)
<span class="kw">ggplot</span>(Hemocrit, <span class="kw">aes</span>(<span class="dt">x=</span>hemocrit, <span class="dt">y=</span>status)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-143-1.png" width="576" /></p>
<p>What if I just naively assume that all professional cyclists are clean? How accurate is this prediction scheme?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(  Hemocrit$status ==<span class="st"> &#39;Clean&#39;</span> )</code></pre></div>
<pre><code>## [1] 0.95</code></pre>
<p>In this case, I am pretty accurate because we correctly classify 95% of the cases! Clearly we should be more intelligent. Lets use the LDA to fit a model that uses hemocrit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">train</span>( status ~<span class="st"> </span>hemocrit, <span class="dt">method=</span><span class="st">&#39;lda&#39;</span>, <span class="dt">data=</span>Hemocrit)
Hemocrit$yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(model)
<span class="kw">table</span>( <span class="dt">Truth=</span>Hemocrit$status, <span class="dt">Predicted=</span>Hemocrit$yhat)</code></pre></div>
<pre><code>##        Predicted
## Truth   Clean Cheat
##   Clean   188     2
##   Cheat     6     4</code></pre>
<p>So this method basically looks to see if the hemocrit level is greater than</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hemocrit %&gt;%<span class="st"> </span><span class="kw">group_by</span>(status) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">xbar=</span><span class="kw">mean</span>(hemocrit))</code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   status     xbar
##   &lt;fctr&gt;    &lt;dbl&gt;
## 1  Clean 47.91675
## 2  Cheat 50.14432</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="fl">47.917</span> +<span class="st"> </span><span class="fl">50.144</span>)/<span class="dv">2</span></code></pre></div>
<pre><code>## [1] 49.0305</code></pre>
<p>and calls them a cheater. Can we choose something a bit more clever? The <code>predict</code> function has an option where it returns the class probabilities. By default, it chooses the category with the highest probability (for two classes than means whichever is greater than 0.50). We can create a different rule that labels somebody a cheater only if the posterior probability is greater than 0.8 or whatever.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">type=</span><span class="st">&#39;prob&#39;</span>)
Hemocrit &lt;-<span class="st"> </span>Hemocrit %&gt;%
<span class="st">  </span><span class="kw">mutate</span>( <span class="dt">phat =</span> pred$Cheat,
          <span class="dt">yhat =</span> <span class="kw">ifelse</span>(phat &lt;=<span class="st"> </span>.<span class="dv">8</span>, <span class="st">&#39;Clean&#39;</span>, <span class="st">&#39;Cheat&#39;</span> ))
<span class="kw">table</span>( <span class="dt">Truth=</span>Hemocrit$status, <span class="dt">Predicted=</span>Hemocrit$yhat)</code></pre></div>
<pre><code>##        Predicted
## Truth   Cheat Clean
##   Clean     0   190
##   Cheat     4     6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(  Hemocrit$status ==<span class="st"> </span>Hemocrit$yhat )</code></pre></div>
<pre><code>## [1] 0.97</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Hemocrit, <span class="kw">aes</span>(<span class="dt">x=</span>hemocrit, <span class="dt">y=</span>status, <span class="dt">color=</span>yhat)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-147-1.png" width="672" /> Great, now we have no false-positives, but a number of folks are getting away with cheating. But what if we back that up, how many false positives do we get… What we want is a graph that compares my false-positive numbers to the true-positives.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">P3 &lt;-<span class="st"> </span>pROC::<span class="kw">roc</span>(Hemocrit$status, Hemocrit$phat)
pROC::<span class="kw">ggroc</span>(P3) </code></pre></div>
<p><img src="Statistical_Computing_Notes_files/figure-html/unnamed-chunk-148-1.png" width="672" /></p>
</div>
</div>
<div id="exercises-3" class="section level2">
<h2><span class="header-section-number">4.6</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>ISL Chapter 4, problem 4: When the number of features p is large, there tends to be a deterioration in the performance of KNN and other local approaches that perform prediction using only observations that are near the test observation for which a prediction must be made. This phenomenon is known as <em>the curse of dimensionality</em>, and it ties into the fact that non-parametric approaches often perform poorly when p is large. We will now investigate this curse.
<ol style="list-style-type: lower-alpha">
<li><p>Suppose that we have a set of observations, each with measurements on <span class="math inline">\(p=1\)</span> feature, <span class="math inline">\(X\)</span>. We assume that <span class="math inline">\(X\)</span> is uniformly (evenly) distributed on <span class="math inline">\([0,1]\)</span>. Associated with each observation is a response value. Suppose that we wish to predict a test observation’s response using only observations that are within 10% of the range of <span class="math inline">\(X\)</span> closest to that test observation. For instance, in order to predict the response for a test observation with <span class="math inline">\(X=0.6\)</span>, we will use observations in the range <span class="math inline">\([0.55, 0.65]\)</span>. On average, what fraction of the available observations will we use to make the prediction?</p></li>
<li>Now suppose that we have a set of observations, each with measurements on <span class="math inline">\(p=2\)</span> features, <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>. We assume that <span class="math inline">\(\left(X_{1},X_{2}\right)\)</span> are uniformly distributed on <span class="math inline">\([0, 1] × [0, 1]\)</span>. We wish to predict a test observation’s response using only observations that are within 10% of the range of <span class="math inline">\(X_{1}\)</span> and within 10% of the range of <span class="math inline">\(X_{2}\)</span> closest to that test observation. For instance, in order to predict the response for a test observation with <span class="math inline">\(X_{1} = 0.6\)</span> and <span class="math inline">\(X_{2} = 0.35\)</span>, we will use observations in the range <span class="math inline">\([0.55, 0.65]\)</span> for <span class="math inline">\(X_{1}\)</span> and in the range <span class="math inline">\([0.3, 0.4]\)</span> for <span class="math inline">\(X_{2}\)</span>. On average, what fraction of the available observations will we use to make the prediction?</li>
<li>Now suppose that we have a set of observations on <span class="math inline">\(p=100\)</span> features. Again the observations are uniformly distributed on each feature, and again each feature ranges in value from 0 to 1. We wish to predict a test observation’s response using observations within the 10% of each feature’s range that is closest to that test observation. What fraction of the available observations will we use to make the prediction?</li>
<li>Using your answers to parts (a)–(c), argue that a drawback of KNN when p is large is that there are very few training observations “near” any given test observation. Even for 3 dimensions, the scheme proposed for KNN can only use approximately 1/1000th of the data, and adding more dimensions just makes this worse. In very high dimensions, the idea of “near” doesn’t really work because in order to be “near” two points must be near in all dimensions and if they are different in any one dimension, then they get classified as being far apart, even if they are identical in the other 99 dimensions.</li>
<li><p>Now suppose that we wish to make a prediction for a test observation by creating a p-dimensional hypercube centered around the test observation that contains, on average, 10% of the training observations. For p = 1, 2, and 100, what is the length of each side of the hypercube? Comment on your answer. <em>Hint: Use the equation from part (c).</em></p></li>
</ol></li>
<li>ISL Chapter 4, problem 5: We now examine the differences between LDA and QDA.
<ol style="list-style-type: lower-alpha">
<li>If the Bayes decision boundary is linear, do we expect LDA or QDA to perform better on the training set? On the test set?</li>
<li>If the Bayes decision boundary is non-linear, do we expect LDA or QDA to perform better on the training set? On the test set?</li>
<li>In general, as the sample size n increases, do we expect the test prediction accuracy of QDA relative to LDA to improve, decline, or be unchanged? Why?</li>
<li>True or False: Even if the Bayes decision boundary for a given problem is linear, we will probably achieve a superior test error rate using QDA rather than LDA because QDA is flexible enough to model a linear decision boundary. Justify your answer.</li>
</ol></li>
<li>ISL Chapter 4, problem 6: Suppose we collect data for a group of students in a statistics class with variables <span class="math inline">\(X_{1}\)</span> = hours studied, <span class="math inline">\(X_{2}\)</span> = undergrad GPA, and <span class="math inline">\(Y\)</span> = receive an A. We fit a logistic regression and produce estimated coefficient, <span class="math inline">\(\hat{\beta}_0=-6\)</span>, <span class="math inline">\(\hat{\beta}_1=0.05\)</span>, <span class="math inline">\(\hat{\beta}_2=1\)</span>.
<ol style="list-style-type: lower-alpha">
<li>Estimate the probability that a student who studies for 40 hours and has an undergrad GPA of 3.5 gets an A in the class.</li>
<li>How many hours would the student in part (a) need to study to have a 50% chance of getting an A in the class?</li>
</ol></li>
<li><p>ISL Chapter 4, problem 8: Suppose that we take a data set, divide it into equally-sized training and test sets, and then try out two different classification procedures. First we use logistic regression and get an error rate of 20% on the training data and 30% on the test data. Next we use 1-nearest neighbors (i.e. K = 1) and get an average error rate (averaged over both test and training data sets) of 18%. Based on these results, which method should we prefer to use for classification of new observations? Why?</p></li>
<li>ISL Chapter 4, problem 11: In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the <code>Auto</code> data set that is included in the package <code>ISLR</code>.
<ol style="list-style-type: lower-alpha">
<li>Create a binary variable, <code>mpg01</code>, that contains a 1 if mpg contains a value above its median, and a 0 if mpg contains a value below its median. You can compute the median using the <code>median()</code> function. Add this column to the <code>Auto</code> data set. <em>Hint: You also need to make sure this is a factor or else your modeling functions will complain. Use the <code>factor()</code> command to do so.</em></li>
<li>Explore the data graphically in order to investigate the association between mpg01 and the other features. Which of the other features seem most likely to be useful in predicting mpg01? Scatterplots and boxplots may be useful tools to answer this question. Describe your findings.</li>
<li>Split the data into equally sized training and test sets.</li>
<li>Perform LDA on the training data in order to predict mpg01 using the variables that seemed most associated with <code>mpg01</code> in (b). What is the test error of the model obtained?</li>
<li>Perform QDA on the training data in order to predict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?</li>
<li>Perform logistic regression on the training data in order to predict <code>mpg01</code> using the variables that seemed most associated with <code>mpg01</code> in (b). What is the test error of the model obtained?</li>
<li>Perform KNN on the training data, with several values of K, in order to predict <code>mpg01</code>. Use only the variables that seemed most associated with <code>mpg01</code> in (b). What test errors do you obtain? Which value of K seems to perform the best on this data set?</li>
</ol></li>
<li><p>ISL Chapter 4, problem 13: Using the <code>ISLR::Boston</code> data set, fit classification models in order to predict whether a given suburb has a crime rate above or below the median. Explore logistic regression, LDA, and KNN models using various subsets of the predictors. Describe your findings.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="3-overview-of-statistical-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5-resampling-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/578/raw/master/04_Classification_LDA.Rmd",
"text": "Edit"
},
"download": [["Statistical_Computing_Notes.pdf", "PDF"], ["Statistical_Computing_Notes.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
